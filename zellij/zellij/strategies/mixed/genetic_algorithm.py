# @Author: Thomas Firmin <ThomasFirmin>
# @Date:   2022-05-03T15:41:48+02:00
# @Email:  thomas.firmin@univ-lille.fr
# @Project: Zellij
# @Last modified by:   tfirmin
# @Last modified time: 2023-04-06T17:28:46+02:00
# @License: CeCILL-C (http://www.cecill.info/index.fr.html)


from zellij.core.metaheuristic import Metaheuristic
from zellij.core.addons import Mutator, Selector, Crossover
from deap import creator, base, tools
import numpy as np

import logging

logger = logging.getLogger("zellij.GA")


creator.create("FitnessMin", base.Fitness, weights=(-1.0,))

# Define what an individual is for the algorithm
creator.create("Individual", list, fitness=creator.FitnessMin)  # type: ignore


class Genetic_algorithm(Metaheuristic):

    """Genetic_algorithm

    Genetic_algorithm (GA) implements a classic genetic algorithm.

    It uses `DEAP <https://deap.readthedocs.io/>`__.
    See :ref:`meta` for more info.

    Attributes
    ----------

    search_space : Searchspace
        Search space object containing bounds of the search space.

    pop_size : int
        Population size.

    elitism : float
        Percentage of the best parents to keep in the next population by replacing the worst children.

    verbose : boolean, default=True
        Algorithm verbosity

    init_pop : boolean, default=None
        If a a initial population (list of individuals) is given.
        The population will be initialized with :code:`init_pop`,
        otherwise randomly .


    See Also
    --------
    :ref:`meta` : Parent class defining what a Metaheuristic is in Zellij.
    :ref:`lf` : Describes what a loss function is in Zellij.
    :ref:`sp` : Describes what a search space is in Zellij.

    Examples
    --------
    >>> from zellij.core import Loss, Threshold, Experiment
    >>> from zellij.core import ContinuousSearchspace, FloatVar, ArrayVar
    >>> from zellij.utils.neighborhoods import FloatInterval, ArrayInterval, Intervals
    >>> from zellij.strategies.genetic_algorithm import Genetic_algorithm
    >>> from zellij.utils.operators import NeighborMutation, DeapTournament, DeapOnePoint
    >>> from zellij.utils.benchmarks import himmelblau
    ...
    >>> lf = Loss()(himmelblau)
    >>> sp = ContinuousSearchspace(ArrayVar(
    ...                           FloatVar("a",-5,5, neighbor=FloatInterval(0.5)),
    ...                           FloatVar("b",-5,5,neighbor=FloatInterval(0.5)),
    ...                           neighbor=ArrayInterval())
    ...                         ,lf, neighbor=Intervals(),
    ...                         mutation = NeighborMutation(0.5),
    ...                         selection = DeapTournament(3),
    ...                         crossover = DeapOnePoint())
    ...
    >>> stop = Threshold(lf, 'calls', 100)
    >>> ga = Genetic_algorithm(sp, pop_size=25,elitism=0.5)
    >>> exp = Experiment(ga, stop)
    >>> exp.run()
    >>> print(f"Best solution:f({lf.best_point})={lf.best_score}")
    """

    def __init__(
        self,
        search_space,
        pop_size=10,
        elitism=0.5,
        verbose=True,
        init_pop=None,
    ):
        """__init__(search_space, pop_size = 10, verbose=True)

        Initialize Genetic_algorithm class

        Parameters
        ----------
        search_space : Searchspace
            Search space object containing bounds of the search space.

        pop_size : int
            Population size.

        elitism : float
            Percentage of the best parents to keep in the next population by replacing the worst children.

        verbose : boolean, default=True
            Algorithm verbosity

        init_pop : boolean, default=None
            If a a initial population (list of individuals) is given.
            The population will be initialized with :code:`init_pop`,
            otherwise randomly .

        """

        super().__init__(search_space, verbose)
        assert hasattr(search_space, "mutation") and isinstance(
            search_space.mutation, Mutator
        ), f"""When using :ref:`ga`, :ref:`sp` must have a `mutation` operator
        and of type: Mutator, use `mutation` kwarg when defining the :ref:`sp`
        ex:\n
        >>> ContinuousSearchspace(values, loss, mutation=...)"""

        assert hasattr(search_space, "selection") and isinstance(
            search_space.selection, Selector
        ), f"""When using :ref:`ga`, :ref:`sp` must have a `selection` operator
        and of type: Selector, use `mutation` kwarg when defining the :ref:`sp`
        ex:\n
        >>> ContinuousSearchspace(values, loss, selection=...)"""

        assert hasattr(search_space, "crossover") and isinstance(
            search_space.crossover, Crossover
        ), f"""When using :ref:`ga`, :ref:`sp` must have a `mutation` operator
        and of type: Selector, use `crossover` kwarg when defining the :ref:`sp`
        ex:\n
        >>> ContinuousSearchspace(values, loss, crossover=...)"""

        ##############
        # PARAMETERS #
        ##############

        self.pop_size = pop_size
        self.elitism = elitism
        self.init_pop = init_pop

        #############
        # VARIABLES #
        #############

        self.initialized = False
        self.first_offspring = False
        self.pop = []

        self.g = 0

        logger.info("Constructing tools...")

        # toolbox contains all the operator of GA. (mutate, select, crossover...)
        self.toolbox = base.Toolbox()

    @property
    def toolbox(self):
        return self._toolbox

    @toolbox.setter
    def toolbox(self, value):
        self._toolbox = value

        # Create operators
        self.search_space.mutation._build(value)
        self.search_space.selection._build(value)
        self.search_space.crossover._build(value)

        # Create a tool to select best individuals from a population
        bpn = int(self.pop_size * self.elitism)
        bcn = self.pop_size - bpn
        value.register("best_p", tools.selBest, k=bpn)
        value.register("best_c", tools.selBest, k=bcn)

        value.register(
            "individual_guess",
            self.initIndividual,
            creator.Individual,  # type: ignore
        )
        value.register(
            "population_guess",
            self.initPopulation,
            list,
            self.toolbox.individual_guess,
        )

        # Determine what an individual is
        value.register("hyperparameters", self.search_space.random_point)

        # Determine the way to build individuals for the population
        value.register(
            "individual",
            tools.initRepeat,
            creator.Individual,  # type: ignore
            value.hyperparameters,
            n=1,
        )

        # Determine the way to build a population
        value.register(
            "population",
            tools.initRepeat,
            list,
            value.individual,
        )

    # Initialize an individual extracted from a file
    def initIndividual(self, icls, content):
        """initIndividual(self, icls, content)

        Initialize an individual to DEAP.

        """
        return icls([content])

    # Initialize a population extracted from a file
    def initPopulation(self, pcls, ind_init, X):
        """initPopulation(self, pcls, ind_init, X)

        Initialize a population of individual, from a given population.

        """

        return pcls(ind_init(c) for index, c in enumerate(X))

    def reset(self):
        """reset()

        Reset GA variables to their initial values.

        """
        self.initialized = False
        self.first_offspring = False

    # Run GA
    def forward(self, X, Y):
        """forward(X, Y)
        Runs one step of Genetic_algorithm.

        Parameters
        ----------
        X : list
            List of previously computed points
        Y : list
            List of loss value linked to :code:`X`.
            :code:`X` and :code:`Y` must have the same length.

        Returns
        -------
        points
            Return a list of new points to be computed with the :ref:`lf`.
        info
            Additionnal information linked to :code:`points`

        """

        logger.info("GA Starting")

        if not self.initialized:
            self.g = 0
            # Start from a saved population
            if self.init_pop:
                logger.info("Creation of the initial population...")
                pop = self.toolbox.population_guess(self.init_pop)

            # Start from a random population
            else:
                # Build the population
                logger.info("Creation of the initial population...")
                pop = self.toolbox.population(n=self.pop_size)

            logger.info("Evaluating the initial population...")
            solutions = [p[0] for p in pop]

            self.initialized = True

            return solutions, {"algorithm": "GA", "generation": 0}

        o_fitnesses = Y
        offspring = self.toolbox.population_guess(X)

        # Map computed fitness to individual fitness value
        for ind, fit in zip(offspring, o_fitnesses):
            ind.fitness.values = (fit,)

        if self.first_offspring:
            # Build new population
            self.pop[:] = self.toolbox.best_p(self.pop) + self.toolbox.best_c(offspring)

        else:
            # Initialize computed population
            self.pop = offspring[:]
            self.first_offspring = True

        self.g += 1

        logger.debug(f"Generation: {self.g}")

        # Selection operator
        logger.debug("Selection...")

        offspring = self.search_space.selection(self.pop, k=len(self.pop))

        children = []

        # Crossover operator
        logger.debug("Crossover...")

        i = 0
        for child1, child2 in zip(offspring[::2], offspring[1::2]):
            # Clone individuals from crossover
            children1 = self.toolbox.clone(child1)
            children2 = self.toolbox.clone(child2)

            # Apply crossover
            self.search_space.crossover(children1[0], children2[0])
            # Delete children fitness inherited from the parents
            del children1.fitness.values
            del children2.fitness.values

            # Add new children to list
            children.append(children1)
            children.append(children2)

        # Mutate children
        logger.debug("Mutation...")

        for mutant in children:
            self.toolbox.mutate(mutant[0])

        solutions = [p[0] for p in children]

        # End population evaluation
        logger.info(f"Evaluating n°{self.g}...")

        return solutions, {"algorithm": "GA", "generation": self.g}

    def __getstate__(self):
        state = self.__dict__.copy()
        del state["_toolbox"]
        return state

    def __setstate__(self, state):
        self.__dict__.update(state)
        self.toolbox = base.Toolbox()


class Steady_State_GA(Metaheuristic):

    """Steady_State_GA

    Steady State genetic algorithm.

    It uses `DEAP <https://deap.readthedocs.io/>`__.
    See :ref:`meta` for more info.

    Attributes
    ----------

    pop_size : int
        Initial population size.

    generation : int
        Generation number of the GA.

    elitism : float, default=0.5
        Percentage of the best parents to keep in the next population by replacing the worst children.
        Default 50%.


    See Also
    --------
    :ref:`meta` : Parent class defining what a Metaheuristic is in Zellij.
    :ref:`lf` : Describes what a loss function is in Zellij.
    :ref:`sp` : Describes what a search space is in Zellij.

    Examples
    --------
    >>> from zellij.core import Loss
    >>> from zellij.core import ContinuousSearchspace
    >>> from zellij.core import FloatVar, ArrayVar
    >>> from zellij.utils.neighborhoods import FloatInterval, ArrayInterval, Intervals
    >>> from zellij.strategies.genetic_algorithm import Genetic_algorithm
    >>> from zellij.utils.operators import NeighborMutation, DeapTournament, DeapOnePoint
    >>> from zellij.utils.benchmarks import himmelblau
    ...
    >>> lf = Loss()(himmelblau)
    >>> sp = ContinuousSearchspace(ArrayVar(
    ...                           FloatVar("a",-5,5, neighbor=FloatInterval(0.5)),
    ...                           FloatVar("b",-5,5,neighbor=FloatInterval(0.5)),
    ...                           neighbor=ArrayInterval())
    ...                         ,lf, neighbor=Intervals(),
    ...                         mutation = NeighborMutation(0.5),
    ...                         selection = DeapTournament(3),
    ...                         crossover = DeapOnePoint())
    ...
    >>> ga = Genetic_algorithm(sp, 1000, pop_size=25, generation=40,elitism=0.5)
    >>> ga.run()
    """

    def __init__(
        self,
        search_space,
        pop_size=10,
        verbose=True,
    ):
        """__init__(search_space, pop_size = 10, verbose=True)

        Initialize Genetic_algorithm class

        Parameters
        ----------
        search_space : Searchspace
            Search space object containing bounds of the search space.

        pop_size : int
            Population size.

        verbose : boolean, default=True
            Algorithm verbosity

        """

        super().__init__(search_space, verbose)
        assert hasattr(search_space, "mutation") and isinstance(
            search_space.mutation, Mutator
        ), f"""When using :ref:`ga`, :ref:`sp` must have a `mutation` operator
        and of type: Mutator, use `mutation` kwarg when defining the :ref:`sp`
        ex:\n
        >>> ContinuousSearchspace(values, loss, mutation=...)"""

        assert hasattr(search_space, "selection") and isinstance(
            search_space.selection, Selector
        ), f"""When using :ref:`ga`, :ref:`sp` must have a `selection` operator
        and of type: Selector, use `mutation` kwarg when defining the :ref:`sp`
        ex:\n
        >>> ContinuousSearchspace(values, loss, selection=...)"""

        assert hasattr(search_space, "crossover") and isinstance(
            search_space.crossover, Crossover
        ), f"""When using :ref:`ga`, :ref:`sp` must have a `mutation` operator
        and of type: Selector, use `crossover` kwarg when defining the :ref:`sp`
        ex:\n
        >>> ContinuousSearchspace(values, loss, crossover=...)"""

        ##############
        # PARAMETERS #
        ##############

        self.pop_size = pop_size
        self.pop = []
        #############
        # VARIABLES #
        #############

        self.initialized = False
        self.first_offspring = False

        logger.info("Constructing tools...")

        # toolbox contains all the operator of GA. (mutate, select, crossover...)
        self.toolbox = base.Toolbox()

    @property
    def toolbox(self):
        return self._toolbox

    @toolbox.setter
    def toolbox(self, value):
        self._toolbox = value

        # Create operators
        self.search_space.mutation._build(value)
        self.search_space.selection._build(value)
        self.search_space.crossover._build(value)

        value.register(
            "individual_guess",
            self.initIndividual,
            creator.Individual,  # type: ignore
        )
        value.register(
            "population_guess",
            self.initPopulation,
            list,
            self.toolbox.individual_guess,
        )

        # Determine what an individual is
        value.register("hyperparameters", self.search_space.random_point)

        # Determine the way to build individuals for the population
        value.register(
            "individual",
            tools.initRepeat,
            creator.Individual,  # type: ignore
            value.hyperparameters,
            n=1,
        )

        # Determine the way to build a population
        value.register(
            "population",
            tools.initRepeat,
            list,
            value.individual,
        )

    # Initialize an individual extracted from a file
    def initIndividual(self, icls, content):
        """initIndividual(self, icls, content)

        Initialize an individual to DEAP.

        """
        return icls([content])

    # Initialize a population extracted from a file
    def initPopulation(self, pcls, ind_init, X):
        """initPopulation(self, pcls, ind_init, X)

        Initialize a population of individual, from a given population.

        """

        return pcls(ind_init(c) for index, c in enumerate(X))

    def reset(self):
        """reset()

        Reset GA variables to their initial values.

        """
        self.initialized = False
        self.first_offspring = False

    def _do_selcrossmut(self):
        # Selection operator
        logger.debug("Selection...")

        new_x = []
        selected = self.search_space.selection(self.pop, k=2)

        # Clone individuals from crossover
        children1 = self.toolbox.clone(selected[0])
        children2 = self.toolbox.clone(selected[1])

        # Crossover operator
        logger.debug("Crossover...")

        # Apply crossover
        self.search_space.crossover(children1[0], children2[0])
        # Delete children fitness inherited from the parents
        del children1.fitness.values
        del children2.fitness.values

        # Add new children to list
        new_x.append(children1)
        new_x.append(children2)

        # Mutate children
        logger.debug("Mutation...")
        self.toolbox.mutate(new_x[0][0])
        self.toolbox.mutate(new_x[1][0])

        solutions = [p[0] for p in new_x]

        return solutions

    # Run GA
    def forward(self, X, Y):
        """forward(X, Y)
        Runs one step of Genetic_algorithm.

        Parameters
        ----------
        X : list
            List of previously computed points
        Y : list
            List of loss value linked to :code:`X`.
            :code:`X` and :code:`Y` must have the same length.

        Returns
        -------
        points
            Return a list of new points to be computed with the :ref:`lf`.
        info
            Additionnal information linked to :code:`points`

        """
        if not self.initialized:
            logger.info("GA Starting")
            self.pop = []
            if X:
                self.initialized = True
                if not Y:
                    return X, {"algorithm": "GA"}
                else:
                    # Map computed fitness to individual fitness value
                    for ind, fit in zip(self.pop, Y):
                        ind.fitness.values = (fit,)
                    return self._do_selcrossmut(), {"algorithm": "SGA"}
            else:
                logger.info("Creation of the initial population...")

                # Build the population
                new_pop = self.toolbox.population(n=self.pop_size)

                logger.info("Evaluating the initial population...")
                solutions = [p[0] for p in new_pop]

                self.initialized = True

                return solutions, {"algorithm": "GA"}

        if (X and Y) and (len(X) > 0 and len(Y) > 0):
            children = []
            # Map computed fitness to individual fitness value
            for ind, fit in zip(X, Y):
                if np.isfinite(fit):
                    ind = self.toolbox.individual_guess(ind)
                    ind.fitness.values = (fit,)
                    children.append(ind)

            if len(children) > 0:
                offspring = self.pop + children
                min_pop = np.minimum(len(offspring), self.pop_size)
                self.pop = tools.selBest(offspring, k=min_pop)

        if len(self.pop) >= self.pop_size:
            sol = self._do_selcrossmut()
            return sol, {"algorithm": "GA"}
        else:
            return [self.search_space.random_point(1)], {"algorithm": "SGA"}

    def __getstate__(self):
        state = self.__dict__.copy()
        del state["_toolbox"]
        return state

    def __setstate__(self, state):
        self.__dict__.update(state)
        self.toolbox = base.Toolbox()
